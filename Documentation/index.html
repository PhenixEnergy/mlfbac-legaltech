<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LegalTech Project Documentation</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8f9fa;
        }
        h1, h2, h3, h4 {
            color: #2c3e50;
            margin-top: 1.5em;
            border-bottom: 1px solid #eee;
            padding-bottom: 0.3em;
        }
        h1 {
            font-size: 2.5em;
            text-align: center;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
            margin-bottom: 30px;
        }
        h2 {
            font-size: 1.8em;
            color: #3498db;
        }
        h3 {
            font-size: 1.5em;
            color: #2980b9;
        }
        p {
            margin-bottom: 1em;
            text-align: justify;
        }
        .container {
            display: flex;
            flex-wrap: wrap;
            justify-content: space-between;
            margin-top: 40px;
        }
        .card {
            background-color: white;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            margin-bottom: 30px;
            width: 48%;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
            overflow: hidden;
        }
        .card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 20px rgba(0,0,0,0.15);
        }
        .card-header {
            background-color: #3498db;
            color: white;
            padding: 15px 20px;
            font-weight: bold;
            font-size: 1.3em;
        }
        .card-body {
            padding: 20px;
            min-height: 180px;
        }
        .card-footer {
            background-color: #f5f5f5;
            padding: 12px 20px;
            text-align: right;
            border-top: 1px solid #eee;
        }
        .btn {
            display: inline-block;
            padding: 8px 15px;
            background-color: #3498db;
            color: white;
            text-decoration: none;
            border-radius: 4px;
            transition: background-color 0.3s ease;
        }
        .btn:hover {
            background-color: #2980b9;
        }
        .section {
            background-color: white;
            padding: 20px;
            margin-bottom: 30px;
            border-radius: 5px;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }
        .toc {
            background-color: #f5f5f5;
            padding: 20px;
            border-radius: 5px;
            margin-bottom: 30px;
        }
        .toc ul {
            list-style-type: none;
            padding-left: 20px;
        }
        .toc li {
            margin-bottom: 10px;
            padding-left: 20px;
            position: relative;
        }
        .toc li::before {
            content: "►";
            position: absolute;
            left: 0;
            color: #3498db;
        }
        .toc a {
            color: #2c3e50;
            text-decoration: none;
        }
        .toc a:hover {
            color: #3498db;
            text-decoration: underline;
        }
        footer {
            text-align: center;
            margin-top: 50px;
            padding-top: 20px;
            border-top: 1px solid #ddd;
            color: #7f8c8d;
        }
        .project-info {
            background-color: #ebf5fb;
            border-left: 4px solid #3498db;
            padding: 15px;
            margin: 20px 0;
        }
        @media (max-width: 768px) {
            .card {
                width: 100%;
            }
        }
    </style>
</head>
<body>
    <h1>LegalTech Project Documentation</h1>
    
    <div class="project-info">
        <p><strong>Projekt:</strong> Aufbereitung juristischer Gutachtentexte für Sprachmodell-Training</p>
        <p><strong>Version:</strong> 2.0 (Mai 2025)</p>
        <p><strong>Autor:</strong> LegalTech Team</p>
    </div>
    
    <div class="section toc">
        <h2>Inhaltsverzeichnis</h2>
        <ul>
            <li><a href="#overview">Projektübersicht</a></li>
            <li><a href="#documentation">Dokumentation</a></li>
            <li><a href="#scripts">Skripte</a></li>
            <li><a href="#workflows">Workflows und Anwendungsbeispiele</a></li>
            <li><a href="#datasets">Datensätze</a></li>
            <li><a href="#technical">Technische Details</a>
                <ul>
                    <li><a href="mathematical_background.html">Mathematische Grundlagen</a></li>
                    <li><a href="segmentierung_visualisierung.html">Segmentierungsvisualisierung</a></li>
                    <li><a href="dataset_structure.html">Datensatzstruktur</a></li>
                </ul>
            </li>
        </ul>
    </div>
    
    <div class="section" id="overview">
        <h2>Projektübersicht</h2>
        <p>
            Dieses Projekt entwickelt eine spezialisierte Pipeline zur Verarbeitung juristischer Texte (insbesondere 
            Rechtsgutachten) für das Training von Sprachmodellen. Die Hauptherausforderung besteht darin, die komplexe 
            Struktur juristischer Texte zu erhalten und gleichzeitig geeignete Trainingsbeispiele zu generieren, 
            die für das Modelltraining optimiert sind.
        </p>
        <p>
            Die entwickelten Skripte ermöglichen:
        </p>
        <ul>
            <li>Konvertierung zwischen JSON und JSONL Formaten für effiziente Datenverarbeitung</li>
            <li>Intelligente Segmentierung juristischer Texte basierend auf semantischen und strukturellen Merkmalen</li>
            <li>Generierung kontextueller Prompts für jedes Segment, basierend auf seinem Inhalt und rechtlichen Kontext</li>
            <li>Anpassbare Ausgabeformatierung für verschiedene Trainingsansätze</li>
        </ul>
    </div>
    
    <div id="documentation">
        <h2>Dokumentation</h2>
        <div class="container">
            <div class="card">
                <div class="card-header">Skriptdokumentation</div>
                <div class="card-body">
                    <p>Umfassende Dokumentation der drei Hauptskripte: jsonl_converter.py, segment_and_prepare_training_data.py und semantic_segmentation.py. Enthält detaillierte Erklärungen der Funktionen, Parameter und Beispiele für typische Anwendungsfälle.</p>
                </div>
                <div class="card-footer">
                    <a href="script_documentation.html" class="btn">Zur Dokumentation</a>
                </div>
            </div>
            
            <div class="card">
                <div class="card-header">Mathematische Grundlagen</div>
                <div class="card-body">
                    <p>Detaillierte Erläuterung der mathematischen Prinzipien hinter der semantischen Segmentierung, einschließlich Vektorrepräsentation juristischer Texte, Ähnlichkeitsmetriken und Algorithmen zur Erkennung thematischer Grenzen.</p>
                </div>
                <div class="card-footer">
                    <a href="mathematical_background.html" class="btn">Zu den Grundlagen</a>
                </div>
            </div>
            
            <div class="card">
                <div class="card-header">Segmentierungsvisualisierung</div>
                <div class="card-body">
                    <p>Visuelle Darstellung verschiedener Segmentierungsmethoden anhand eines Beispieltextes. Zeigt, wie Texte durch Hauptüberschriften, nummerierte Überschriften, Schlüsselwörter, juristische Wendungen und semantische Analyse segmentiert werden.</p>
                </div>
                <div class="card-footer">
                    <a href="segmentierung_visualisierung.html" class="btn">Zur Visualisierung</a>
                </div>
            </div>
            
            <div class="card">
                <div class="card-header">Datensatzstruktur</div>
                <div class="card-body">
                    <p>Erklärung der Datensatzstruktur und Transformationsprozesse. Beschreibt das Eingabe-, Zwischen- und Ausgabeformat sowie die Namenskonventionen und Statistiken zur Segmentierungsqualität.</p>
                </div>
                <div class="card-footer">
                    <a href="dataset_structure.html" class="btn">Zur Datenstruktur</a>
                </div>
            </div>
        </div>
    </div>
    
    <div class="section" id="scripts">
        <h2>Skripte</h2>
        <h3>Hauptskripte</h3>
        <ul>
            <li>
                <strong>jsonl_converter.py</strong> - Konvertiert zwischen JSON und JSONL Formaten mit automatischer Formaterkennung
            </li>
            <li>
                <strong>segment_and_prepare_training_data.py</strong> - Segmentiert juristische Texte und bereitet sie für das Training vor
            </li>
            <li>
                <strong>semantic_segmentation.py</strong> - Implementiert fortgeschrittene semantische Segmentierungsmethoden
            </li>
        </ul>
        
        <h3>Script Ausführung</h3>
        <p>Alle Skripte befinden sich im <code>Scripts/</code> Verzeichnis und können direkt über die Kommandozeile ausgeführt werden:</p>
        <pre>
cd c:\Ab 20.05.2025\Scripts
python jsonl_converter.py -i ../Dataset/gutachten_alle_seiten_neu.json -o ../Dataset/gutachten_alle_seiten_neu.jsonl
python segment_and_prepare_training_data.py -i ../Dataset/gutachten_alle_seiten_neu.jsonl -l 1500000</pre>
    </div>
    
    <div class="section" id="workflows">
        <h2>Workflows und Anwendungsbeispiele</h2>
        <h3>Standardworkflow</h3>
        <ol>
            <li>Konvertiere Eingabedaten von JSON zu JSONL für effiziente Verarbeitung</li>
            <li>Segmentiere und bereite die Texte mit einem Token-Limit vor</li>
            <li>Verwende die generierten Trainingsdaten für das Finetuning eines Sprachmodells</li>
        </ol>
        
        <h3>Erweiterte Anwendungsfälle</h3>
        <ul>
            <li>Verarbeitung nur bestimmter Rechtsbereiche über Normfilterung (-in, -ex Flags)</li>
            <li>Generierung von Content-Only Datasets ohne Prompts (-c Flag)</li>
            <li>Einzelverarbeitung spezifischer Gutachten zur Qualitätskontrolle</li>
            <li>Zurückkonvertierung von JSONL zu JSON für bestimmte Toolintegrationen</li>
        </ul>
        
        <p>Detaillierte Beispiele für alle Workflows finden Sie in der <a href="script_documentation.html#workflow">Skriptdokumentation</a>.</p>
    </div>
    
    <div class="section" id="datasets">
        <h2>Datensätze</h2>
        <h3>Verfügbare Datensätze</h3>
        <ul>
            <li>
                <strong>gutachten_alle_seiten_neu.json</strong><br>
                Originaler Rohdatensatz mit unbearbeiteten juristischen Gutachten
            </li>
            <li>
                <strong>gutachten_alle_seiten_neu_1_5_Mio_segmented_prepared.jsonl</strong><br>
                Segmentierter Datensatz mit 1,5 Millionen Token, optimiert für Modelltraining
            </li>
            <li>
                <strong>gutachten_alle_seiten_neu_2_Mio_segmented_prepared.jsonl</strong><br>
                Erweiterter segmentierter Datensatz mit 2 Millionen Token
            </li>
            <li>
                <strong>gutachten_alle_seiten_neu_max_segmented_prepared.jsonl</strong><br>
                Vollständiger segmentierter Datensatz ohne Token-Limit
            </li>
        </ul>
        
        <h3>Datensatzstatistiken</h3>
        <ul>
            <li>Durchschnittliche Segmente pro Dokument: 4,2</li>
            <li>Durchschnittliche Tokens pro Segment: 850</li>
            <li>Segmentierungserfolgsrate: 93%</li>
            <li>Beste Segmentierungsmethode: Semantische Segmentierung (93% Erfolgsrate)</li>
        </ul>
        
        <p>Weitere Details zur Datensatzstruktur und -statistik finden Sie in der <a href="dataset_structure.html">Datensatzstruktur-Dokumentation</a>.</p>
    </div>
    
    <div class="section" id="technical">
        <h2>Technische Details</h2>
        <h3>Systemanforderungen</h3>
        <ul>
            <li>Python 3.8 oder höher</li>
            <li>Ausreichend Arbeitsspeicher für die Verarbeitung großer JSON-Dateien</li>
            <li>Für die semantische Segmentierung wird empfohlen: min. 8GB RAM</li>
        </ul>
        
        <h3>Verwendete Bibliotheken</h3>
        <ul>
            <li>Standard Python-Bibliotheken: json, re, os, argparse</li>
            <li>Keine externen Abhängigkeiten erforderlich</li>
        </ul>
    </div>
    
    <footer>
        <p>LegalTech-Projekt | Zentrale Dokumentation | Erstellt: Mai 2025</p>
    </footer>
</body>
</html>
