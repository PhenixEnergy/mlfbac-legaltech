#!/usr/bin/env python3
"""
Vollst√§ndige Datenbank-Bef√ºllung mit ALLEN DNOTI-Gutachten
L√§dt alle 3.936 Gutachten in die ChromaDB
"""
import json
import sys
import os
from pathlib import Path
import time
from datetime import datetime

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

def load_all_gutachten():
    print("üöÄ VOLLST√ÑNDIGE DATENBANK-BEF√úLLUNG")
    print("=" * 60)
    print(f"‚è∞ Start: {datetime.now().strftime('%H:%M:%S')}")
    
    # 1. Load data file
    data_file = Path("Database/Original/dnoti_all.json")
    if not data_file.exists():
        print(f"‚ùå Data file not found: {data_file}")
        return False
    
    print(f"üìÑ Loading JSON data from: {data_file}")
    with open(data_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"‚úÖ Loaded {len(data)} Gutachten from JSON")
      # 2. Import ChromaDB
    try:
        import chromadb
        from chromadb.utils import embedding_functions
        print("‚úÖ ChromaDB imported successfully")
    except ImportError as e:
        print(f"‚ùå ChromaDB import failed: {e}")
        return False
    
    # 3. Create ChromaDB client
    print("üíæ Connecting to ChromaDB...")
    try:
        # Verwende neue Konfiguration
        from src.config import config
        chroma_path = config.CHROMA_PERSIST_DIRECTORY
        os.makedirs(chroma_path, exist_ok=True)
        client = chromadb.PersistentClient(path=chroma_path)
        print(f"‚úÖ Connected to ChromaDB at: {os.path.abspath(chroma_path)}")
    except Exception as e:
        print(f"‚ùå ChromaDB connection failed: {e}")
        return False
    
    # 4. Recreate collection (delete old and create new)
    print("üóëÔ∏è Removing old collection...")
    try:
        client.delete_collection("legal_documents")
        print("‚úÖ Old collection deleted")
    except:
        print("‚ÑπÔ∏è No existing collection to delete")
    
    print("üìö Creating new collection...")
    try:
        # Use our custom embedding function with IBM Granite model from config
        from src.vectordb.chroma_client import GraniteEmbeddingFunction
        embedding_fn = GraniteEmbeddingFunction()  # Uses config.EMBEDDING_MODEL by default
        
        collection = client.create_collection(
            name="legal_documents",
            embedding_function=embedding_fn,
            metadata={
                "hnsw:space": "cosine"  # Use cosine similarity instead of L2
            }
        )
        print("‚úÖ New collection 'legal_documents' created with cosine similarity")
    except Exception as e:
        print(f"‚ùå Collection creation failed: {e}")
        return False
    
    # 5. Process ALL documents
    print(f"üì• Processing ALL {len(data)} Gutachten...")
    print("‚è≥ This will take several minutes...")
    
    total_added = 0
    total_skipped = 0
    batch_size = 25  # Reasonable batch size for stability
    start_time = time.time()
    
    for i in range(0, len(data), batch_size):
        batch = data[i:i+batch_size]
        batch_start = time.time()
        
        try:
            documents = []
            metadatas = []
            ids = []
            
            for j, doc in enumerate(batch):
                doc_id = f"gutachten_{i+j:05d}"                # Get content - the field is called 'text'
                content = doc.get('text', '')
                
                # Clean and validate content
                if not content or len(content.strip()) < 100:  # Skip very short content
                    total_skipped += 1
                    continue
                
                content = content.strip()
                
                # Limit content length for better performance
                if len(content) > 8000:
                    content = content[:8000] + "..."
                
                # Create comprehensive metadata
                metadata = {
                    'source_gutachten_id': str(doc.get('gutachten_nummer', doc.get('id', f'unknown_{i+j}'))),
                    'erscheinungsdatum': str(doc.get('erscheinungsdatum', '')),
                    'rechtsbezug': str(doc.get('rechtsbezug', 'National')),
                    'normen': str(doc.get('normen', '')),
                    'url': str(doc.get('url', '')),
                    'section_type': 'full_gutachten',
                    'level': 1,
                    'token_count': len(content.split()),
                    'char_count': len(content),
                    'original_id': str(doc.get('id', '')),
                    'batch_number': i // batch_size + 1
                }
                  # Extract legal norms as list if possible
                normen_text = doc.get('normen', '')
                if normen_text and normen_text != '':
                    # Split normen by common separators
                    legal_norms = [norm.strip() for norm in normen_text.replace(';', ',').split(',') if norm.strip()]
                    # Convert list to comma-separated string for ChromaDB compatibility
                    metadata['legal_norms'] = '; '.join(legal_norms[:10])  # Limit to 10 norms
                else:
                    metadata['legal_norms'] = ''
                
                documents.append(content)
                metadatas.append(metadata)
                ids.append(doc_id)
            
            # Add batch to ChromaDB
            if documents:
                collection.add(
                    documents=documents,
                    metadatas=metadatas,
                    ids=ids
                )
                total_added += len(documents)
                
                batch_time = time.time() - batch_start
                estimated_remaining = (batch_time * (len(data) - i - batch_size)) / batch_size / 60
                
                print(f"   ‚úÖ Batch {i//batch_size + 1:3d}/{(len(data)-1)//batch_size + 1}: "
                      f"{len(documents):2d} docs | "
                      f"Total: {total_added:4d} | "
                      f"Time: {batch_time:.1f}s | "
                      f"ETA: {estimated_remaining:.1f}min")
        
        except Exception as e:
            print(f"   ‚ùå Batch {i//batch_size + 1} failed: {e}")
            continue
    
    total_time = time.time() - start_time
    
    print("\n" + "=" * 60)
    print("üìä LOADING COMPLETE!")
    print(f"‚úÖ Successfully added: {total_added:,} Gutachten")
    print(f"‚ö†Ô∏è Skipped (too short): {total_skipped:,} documents")
    print(f"‚è±Ô∏è Total time: {total_time/60:.1f} minutes")
    print(f"üìà Average: {total_added/total_time:.1f} docs/second")
    
    # 6. Verify the database
    print("\nüîç Verifying database...")
    try:
        final_count = collection.count()
        print(f"üìö Final document count: {final_count:,}")
        
        # Test search
        test_results = collection.query(
            query_texts=["Haftung Schadensersatz"],
            n_results=5
        )
        
        found_results = len(test_results.get('ids', [[]])[0])
        print(f"üîç Test query results: {found_results}")
        
        if found_results > 0:
            print("‚úÖ Database is working correctly!")
            
            # Show sample results
            for i, doc in enumerate(test_results['documents'][0][:3]):
                metadata = test_results['metadatas'][0][i]
                gutachten_id = metadata.get('source_gutachten_id', 'N/A')
                print(f"   Sample {i+1}: Gutachten {gutachten_id} - '{doc[:80]}...'")
        else:
            print("‚ùå Test query failed!")
            return False
            
    except Exception as e:
        print(f"‚ùå Verification failed: {e}")
        return False
    
    print(f"\nüéâ VOLLST√ÑNDIGE DATENBANK BEREIT!")
    print(f"üìä {final_count:,} Gutachten verf√ºgbar f√ºr semantische Suche")
    print(f"üåê Testen Sie jetzt in der Streamlit-App: http://localhost:8501")
    print(f"‚è∞ Ende: {datetime.now().strftime('%H:%M:%S')}")
    
    return True

if __name__ == "__main__":
    success = load_all_gutachten()
    if not success:
        print("\n‚ùå Database loading failed!")
        sys.exit(1)
